{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4356f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dc06ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "port_stem = PorterStemmer()\n",
    "#stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8880a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(content):\n",
    "    stemmed_content = re.sub('[^a-zA-Z]',' ',content)\n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    stemmed_content = [ port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    return stemmed_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c043afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF(arr,unique):\n",
    "    result={}\n",
    "    TF=[]\n",
    "    for m,i in enumerate(arr):\n",
    "        dicti={}\n",
    "        for l,j in enumerate(unique):\n",
    "            comb=(m,l)\n",
    "            if j in i:\n",
    "                result[comb]=1\n",
    "                count=0\n",
    "                for idk in i:\n",
    "                    if j ==idk:\n",
    "                        count+=1\n",
    "                dicti[j]=count\n",
    "            else:\n",
    "                dicti[j]=0\n",
    "        ex=list(dicti.values())\n",
    "        for k in range(len(ex)):\n",
    "            ex[k]=ex[k]/len(i)\n",
    "        TF.append(ex)\n",
    "    lst=[]\n",
    "    for i in TF:\n",
    "        for k in i:\n",
    "            if k !=0:\n",
    "                lst.append(k)\n",
    "    for i,k in zip(lst,result):\n",
    "        result[k]=i\n",
    "    return(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d8576d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IDF(result,arr,unique,all_words,product_descriptions1):\n",
    "    dict={}\n",
    "    for j in all_words:\n",
    "        if j not in dict:\n",
    "            dict[j]=1\n",
    "        else:\n",
    "            dict[j]+=1\n",
    "    \n",
    "    for i in dict:\n",
    "        dict[i]= dict[i]=np.log10((len(product_descriptions1)+1)/(dict[i]+1))+1\n",
    "    IDF=[]\n",
    "    for i in arr:\n",
    "        val={}\n",
    "        for j in unique:\n",
    "            if j in i:\n",
    "                val[j]=dict[j]\n",
    "        IDF.append(list(val.values()))\n",
    "    print(IDF,result)\n",
    "    lst=[]\n",
    "    for i in IDF:\n",
    "        for k in i:\n",
    "            if k !=0:\n",
    "                lst.append(k)\n",
    "    \n",
    "    for i,k in zip(lst,result):\n",
    "        print(i*result[k])\n",
    "        result[k]=i*result[k]\n",
    "    return(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49f04b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfdif_vectorizer(corpus):\n",
    "    d=corpus.apply(stemming)\n",
    "    product_descriptions1=d.copy()\n",
    "    arr=d.str.split()\n",
    "    print(arr)\n",
    "    unique=[]\n",
    "    all_words=[]\n",
    "    for i in arr:\n",
    "        for j in i:\n",
    "            all_words.append(j)\n",
    "            if j not in unique:\n",
    "                unique.append(j)\n",
    "    result=TF(arr,unique)\n",
    "    f_result=IDF(result,arr,unique,all_words,product_descriptions1)\n",
    "    \n",
    "    return(f_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a0ec271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              This is the first document.\n",
       "1    This document is the second document.\n",
       "2               And this is the third one.\n",
       "3              Is this the first document?\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?' ]\n",
    "corpus=pd.DataFrame(corpus)\n",
    "corpus=corpus[0]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b04d03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               [first, document]\n",
      "1    [document, second, document]\n",
      "2                    [third, one]\n",
      "3               [first, document]\n",
      "Name: 0, dtype: object\n",
      "[[1.2218487496163564, 1.0], [1.0, 1.3979400086720375], [1.3979400086720375, 1.3979400086720375], [1.2218487496163564, 1.0]] {(0, 0): 0.5, (0, 1): 0.5, (1, 1): 0.6666666666666666, (1, 2): 0.3333333333333333, (2, 3): 0.5, (2, 4): 0.5, (3, 0): 0.5, (3, 1): 0.5}\n",
      "0.6109243748081782\n",
      "0.5\n",
      "0.6666666666666666\n",
      "0.46598000289067915\n",
      "0.6989700043360187\n",
      "0.6989700043360187\n",
      "0.6109243748081782\n",
      "0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(0, 0): 0.6109243748081782,\n",
       " (0, 1): 0.5,\n",
       " (1, 1): 0.6666666666666666,\n",
       " (1, 2): 0.46598000289067915,\n",
       " (2, 3): 0.6989700043360187,\n",
       " (2, 4): 0.6989700043360187,\n",
       " (3, 0): 0.6109243748081782,\n",
       " (3, 1): 0.5}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1=tfdif_vectorizer(corpus)\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c957bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual solve:\n",
    "#with smooth\n",
    "#tf=total no of time word appeared in document/total no of words\n",
    "#idf=log10(total no of documents/no of time that word occured in that document),it help to determine rare word the near\n",
    "                                                                           #to zero the less rare that word is \n",
    "#for \"document\" in sentence 2 : tf=2/3=0.666\n",
    "                              #: idf= log10(4+1/4+1)+1=log(1)+1=0+1=1\n",
    "    \n",
    "#tf*idf=0.666 in doc 2\n",
    "#without smooth:0.666*0="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
